{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "from textstat.textstat import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureCalculator(dataList,nameList):\n",
    "    awl = open(\"/home/sp/nlpfinal/wordlist.txt\",\"r\")\n",
    "    wordList = awl.read()\n",
    "    awlList = set(wordList.split())\n",
    "    \n",
    "    allFeatureDict = {}\n",
    "    awlF = {}\n",
    "    ari = {}\n",
    "    aspw = {}\n",
    "    cole_l_i = {}\n",
    "    dale_c_r = {}\n",
    "    diff_w = {}\n",
    "    flesch_k_g = {}\n",
    "    flesch_e_r = {}\n",
    "    gun_fog = {}\n",
    "    lexi_c = {}\n",
    "    linsear_w = {}\n",
    "    li_x = {}\n",
    "    polysyll_c = {}\n",
    "    text_s = {}\n",
    "    \n",
    "    for i in range(len(nameList)):\n",
    "        \n",
    "        key = nameList[i]\n",
    "        value = dataList[i]\n",
    "        \n",
    "        wordinF = nltk.word_tokenize(value)\n",
    "        j = 0\n",
    "        \n",
    "        totWord = len(wordinF)\n",
    "        for w in wordinF:\n",
    "            if w in awlList:\n",
    "                j += 1\n",
    "        awlF[key] = j/totWord\n",
    "        ari[key] = textstat.automated_readability_index(value)\n",
    "        aspw[key] = textstat.avg_syllables_per_word(value)\n",
    "        cole_l_i[key] = textstat.coleman_liau_index(value)\n",
    "        dale_c_r[key] = textstat.dale_chall_readability_score(value)\n",
    "        diff_w[key] = textstat.difficult_words(value)/totWord\n",
    "        flesch_k_g[key] = textstat.flesch_kincaid_grade(value)\n",
    "        flesch_e_r[key] = textstat.flesch_reading_ease(value)\n",
    "        gun_fog[key] = textstat.gunning_fog(value)\n",
    "        lexi_c[key] = textstat.lexicon_count(value)\n",
    "        linsear_w[key] = textstat.linsear_write_formula(value)\n",
    "        li_x[key] = textstat.lix(value)\n",
    "        polysyll_c[key] = textstat.polysyllabcount(value)\n",
    "        text_s[key] = textstat.text_standard(value)\n",
    "        \n",
    "        \n",
    "    allFeatureDict[\"awlF\"] = awlF\n",
    "    allFeatureDict[\"ari\"]=ari\n",
    "    allFeatureDict[\"aspw\"]=aspw\n",
    "    allFeatureDict[\"cole_l_i\"]=cole_l_i\n",
    "    allFeatureDict[\"dale_c_r\"]=dale_c_r\n",
    "    allFeatureDict[\"diff_w\"]=diff_w\n",
    "    allFeatureDict[\"flesch_k_g\"]=flesch_k_g\n",
    "    allFeatureDict[\"flesch_e_r\"]=flesch_e_r\n",
    "    allFeatureDict[\"gun_fog\"]=gun_fog\n",
    "    allFeatureDict[\"lexi_c\"]=lexi_c\n",
    "    allFeatureDict[\"linsear_w\"]=linsear_w\n",
    "    allFeatureDict[\"li_x\"]=li_x\n",
    "    allFeatureDict[\"polysyll_c\"]=polysyll_c\n",
    "    allFeatureDict[\"text_s\"]=text_s\n",
    "    return allFeatureDict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataReader(flistName,location):\n",
    "    dataList = []\n",
    "    for fname in flistName:\n",
    "        file = open(location+fname,\"r\",encoding=\"cp437\")\n",
    "        data = file.read()\n",
    "        dataList.append(data)\n",
    "    return dataList\n",
    "\n",
    "#Read the Data\n",
    "loc = \"/home/sp/nlpfinal/WeeBit-TextOnly/\"\n",
    "#BitGCSE, BitKS3, WRLevel2, WRLevel3, WRLevel4\n",
    "\n",
    "class1 = loc + \"WRLevel2/\"\n",
    "class2 = loc +  \"WRLevel3/\"\n",
    "class3 = loc +  \"WRLevel4/\"\n",
    "class4 = loc +  \"BitKS3/\"\n",
    "class5 = loc +  \"BitGCSE/\"\n",
    "\n",
    "c1 = os.listdir(class1)\n",
    "c2 = os.listdir(class2)\n",
    "c3 = os.listdir(class3)\n",
    "c4 = os.listdir(class4)\n",
    "c5 = os.listdir(class5)\n",
    "\n",
    "l1Data = dataReader(c1,class1)\n",
    "l2Data = dataReader(c2,class2)\n",
    "l3Data = dataReader(c3,class3)\n",
    "l4Data = dataReader(c4,class4)\n",
    "l5Data = dataReader(c5,class5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = FeatureCalculator(l1Data,c1)\n",
    "f2 = FeatureCalculator(l2Data,c2)\n",
    "f3 = FeatureCalculator(l3Data,c3)\n",
    "f4 = FeatureCalculator(l4Data,c4)\n",
    "f5 = FeatureCalculator(l5Data,c5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffffname = \"lexwr4SyntacticFeature.csv\"#lexwr3SyntacticFeature.csv,lexwr4SyntacticFeature.csv,lexbitks3SyntacticFeature\n",
    "#lexbitgcseSyntacticFeature.csv\n",
    "dd = pd.read_csv(\"All_Features/\"+ffffname)\n",
    "\n",
    "fileListName = dd[\"Filename\"]\n",
    "allFeatureDict = f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "awlF = allFeatureDict[\"awlF\"]\n",
    "ari = allFeatureDict[\"ari\"]\n",
    "aspw = allFeatureDict[\"aspw\"]\n",
    "cole_l_i = allFeatureDict[\"cole_l_i\"]\n",
    "dale_c_r = allFeatureDict[\"dale_c_r\"]\n",
    "diff_w = allFeatureDict[\"diff_w\"]\n",
    "flesch_k_g = allFeatureDict[\"flesch_k_g\"]\n",
    "flesch_e_r = allFeatureDict[\"flesch_e_r\"]\n",
    "gun_fog = allFeatureDict[\"gun_fog\"]\n",
    "lexi_c = allFeatureDict[\"lexi_c\"]\n",
    "linsear_w = allFeatureDict[\"linsear_w\"]\n",
    "li_x = allFeatureDict[\"li_x\"]\n",
    "polysyll_c = allFeatureDict[\"polysyll_c\"]\n",
    "text_s = allFeatureDict[\"text_s\"]\n",
    "\n",
    "\n",
    "awlF_l = []\n",
    "ari_l = []\n",
    "aspw_l = []\n",
    "cole_l_i_l = []\n",
    "dale_c_r_l = []\n",
    "diff_w_l = []\n",
    "flesch_k_g_l = []\n",
    "flesch_e_r_l = []\n",
    "gun_fog_l = []\n",
    "lexi_c_l = []\n",
    "linsear_w_l = []\n",
    "li_x_l = []\n",
    "polysyll_c_l = []\n",
    "text_s_l = []\n",
    "\n",
    "for name in fileListName:\n",
    "    key = name\n",
    "    awlF_l.append(awlF[key])\n",
    "    ari_l.append(ari[key])\n",
    "    aspw_l.append(aspw[key])\n",
    "    cole_l_i_l.append(cole_l_i[key])\n",
    "    dale_c_r_l.append(dale_c_r[key])\n",
    "    diff_w_l.append(diff_w[key])\n",
    "    flesch_k_g_l.append(flesch_k_g[key])\n",
    "    flesch_e_r_l.append(flesch_e_r[key])\n",
    "    gun_fog_l.append(gun_fog[key])\n",
    "    lexi_c_l.append(lexi_c[key])\n",
    "    linsear_w_l.append(linsear_w[key])\n",
    "    li_x_l.append(li_x[key])\n",
    "    polysyll_c_l.append(polysyll_c[key])\n",
    "    text_s_l.append(text_s[key])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd[\"awlF\"]=awlF_l\n",
    "dd[\"ari\"]=ari_l\n",
    "dd[\"aspw\"]=aspw_l\n",
    "dd[\"cole_l_i\"]=cole_l_i_l\n",
    "dd[\"dale_c_r\"]=dale_c_r_l\n",
    "dd[\"diff_w\"]=diff_w_l\n",
    "dd[\"flesch_k_g\"]=flesch_k_g_l\n",
    "dd[\"flesch_e_r\"]=flesch_e_r_l\n",
    "dd[\"gun_fog\"]=gun_fog_l\n",
    "dd[\"lexi_c\"]=lexi_c_l\n",
    "dd[\"linsear_w\"]=linsear_w_l\n",
    "dd[\"li_x\"]=li_x_l\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.to_csv(\"ffff/\"+ffffname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textstat.polysyllabcount"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
